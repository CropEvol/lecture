{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M02_genomics_and_deep_learning.ipynb","provenance":[],"collapsed_sections":["tkxWWj-mfjTA","x5-hGJMo81nf","HVNkN5jMhLUe","G4E0lR8bhOe-"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QZR2MVkqfL1b"},"source":["<img src=\"https://lh3.googleusercontent.com/pw/ACtC-3fFHZrzKpHGWl0vYz7Sr8FX8QqLQ_tc8XHBSwqQnM4hgsIOjtjaOde1M9oHSAfe1Fs2SwVORlapit4-JOz0mjP8Tnz6HetkLZDZb8CifSd0uoSp1Nj3wG_wh1sEQlKXXzvEA9Y9HnQqu2Ecv2igmInb=w1097-h235-no?authuser=0\" alt=\"2020年度ゲノム情報解析入門\" height=\"100px\" align=\"middle\">"]},{"cell_type":"markdown","metadata":{"id":"XLDMJPojfSXb"},"source":["# データ解析体験(2) - ゲノム解析とディープラーニング -"]},{"cell_type":"markdown","metadata":{"id":"tkxWWj-mfjTA"},"source":["## ディープラーニングの歴史\n","<small>引用元: [話題のディープラーニングとは｜過去の歴史とあわせて仕組みを解説](https://service.plan-b.co.jp/blog/dmp/6210/)</small>"]},{"cell_type":"markdown","metadata":{"id":"eYUq-Z2rfoWD"},"source":["**（1943年）「形式ニューロン」の開発**\n","\n","<img src = \"https://service.plan-b.co.jp/wp/wp-content/uploads/blog/deep_learning_01.jpg\" alt = \"filter\" height = \"250px\">\n","\n","例えばある形式ニューロンを、「A君が学校に行くかどうかを判定する分類器」としたとします。A君が学校に行ったとき、行かなかったときのあらゆる情報を集め、この形式ニューロンに学習させる事によって以下のように重みと閾値が決定されます。\n","\n","\n","<img src = \"https://service.plan-b.co.jp/wp/wp-content/uploads/blog/deep_learning_03z.jpg\" alt = \"filter\" height = \"250px\">\n","\n","**（1958年）「パーセプトロン」の開発**\n","\n","形式ニューロンをいくつか並列に組み合わせてから出力ニューロンで束ねるという2層の構造をとる「パーセプトロン」が開発されました。\n","\n","\n","<img src = \"https://service.plan-b.co.jp/wp/wp-content/uploads/blog/deep_learning_04.jpg\" alt = \"filter\" height = \"250px\">\n","\n","**（1986年）「隠れ層」の導入**\n","\n","間に隠れ層と呼ばれるもう一つのニューロンの層を加える事で、線形分離不可能な複雑な問題も扱える様になりました。\n","\n","\n","<img src = \"https://service.plan-b.co.jp/wp/wp-content/uploads/blog/deep_learning_06.jpg\" alt = \"filter\" height = \"250px\">\n","\n","**（2006年）「ディープラーニング」の開発**\n","\n","「ニューラルネットワークの層の数を増やしてもうまく学習する方法」が編み出され、これがディープラーニングと呼ばれる様になりました。\n","\n","\n","<img src = \"https://service.plan-b.co.jp/wp/wp-content/uploads/blog/deep_learning_07.jpg\" alt = \"filter\" height = \"250px\">\n"]},{"cell_type":"markdown","metadata":{"id":"x5-hGJMo81nf"},"source":["## ゲノム解析にディープラーニングを用いる例\n","<small>引用元: [7. 実践編: ディープラーニングを使った配列解析](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/07_DNA_Sequence_Data_Analysis.html)</small>\n"]},{"cell_type":"markdown","metadata":{"id":"VqlltCJZYh8m"},"source":["次世代シーケンサの発展・普及とともに，大量の遺伝子配列が読み取られるようになりました．そうした中で，塩基配列で表現された遺伝子型と病気や形態などの表現型との関係を推定するようなGWAS（Genome Wide Association Study; ゲノムワイド関連解析）が広がってきました．\n","\n","しかし，遺伝子の変異だけでは全ての表現型の変化を説明できないことがわかってきました．特に，非翻訳領域が遺伝子発現に影響を与え，表現型の変化を生じさせていることが様々な実験結果からわかってきています．遺伝子発現時に周辺領域がどのように影響を与えているのかを調べるためにディープラーニングを利用できるのではないでしょうか。\n","\n","**扱うデータ**\n","\n","数百種類の人の細胞型から得られた数千のChIP-seq，DNase-seq（オープンクロマチン領域の網羅的解析の一手法）のデータセットから得られたDNA塩基配列を入力として，CAGE（正確性、定量性に優れたRNAシーケンス手法）の結果計測されたmRNAの発現量を推定する問題を考えます。\n","\n","****\n","<<学習用>>\n","\n","長さが130172bpの配列が5000個あり、それぞれA, T, C, Gの対応する次元の値が1, それ以外は0であるような配列\n","\n","train_in (5000, 131072, 4)\n","\n","長さが1024bpからなる配列が5000個あり,それぞれが10種類の異なるChIP-seqの結果のカバレッジ値\n","\n","train_out (5000, 1024, 10)\n","\n","****\n","\n","<<検証用>>\n","\n","\n","valid_in (500, 131072, 4)\n","\n","valid_out (500, 1024, 10)\n","\n","****\n","\n","<<テスト用>>\n","\n","\n","test_in (500, 131072, 4)\n","\n","test_out (500, 1024, 10)\n","\n","****\n","\n","\n","**モデルとモデルの学習**\n","\n","モデルには配列データを1次元の画像とみなし，画像処理の時と同様な解析を行えるCNN（畳み込みニューラルネットワーク）をモデルとして使います。\n","\n","\n","ただし、\n","\n","\n","・従来のCNN\n","\n","ある位置の入力の情報は各層で**隣接する位置**からしか読み込まれません。今回の問題の場合必要な層数が多くなりすぎてしまい現実的ではありません。\n","\n","<img src = \"http://musyoku.github.io/images/post/2016-09-17/naive_conv.png\" alt = \"filter\" height = \"250px\">\n","\n","・Dilated Convolution（atrous convolutionやconvolution weith holesともよばれます)\n","\n","入力の情報を**離れたところ**からも受け取れる（少ない層で学習できる）のでこちらを学習すべきニューラルネットワークとして採用します。\n","\n","<img src = \"https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif\" alt = \"filter\" height = \"250px\">\n","\n","\n","〜この後の流れ〜\n","\n","**学習用データと検証用データでニューラルネットワークの学習**\n","\n","（参考にしたサイトでは**Chainer**ライブラリを使ってディープラーニングを行っています）\n","\n","**テストデータに対して学習済みのモデルを適用**\n","\n","↓にテストデータを使った検証結果の一部を表示します。ピークをきちんと捉えており、配列データを使ってmRNAの発現量を推定することができました。\n","\n","<img src = \"https://japan-medical-ai.github.io/medical-ai-course-materials/_images/notebooks_07_DNA_Sequence_Data_Analysis_43_1.png\" alt = \"filter\" height = \"400px\">\n","\n","\n","\n","****\n","\n","シーケンスデータソース：Sequential regulatory activity prediction across chromosomes with convolutional neural networks, D. R. Kelly and et al., Genome Res. 2018. 28: 739-750\n","https://genome.cshlp.org/content/28/5/739.full\n"]},{"cell_type":"markdown","metadata":{"id":"6BPFULUCyRqK"},"source":["## Keras/Tensorflow で手書き文字の画像分類\n","\n","MNISTは手書きの数字を白黒画像にしたデータです。\n","\n"," ここでは人工知能ライブラリ Keras で MNIST データを学習させ、手書き数字を認識できる**人工知能**を作ります。\n","\n","\n","\n","Kerasを使用すると、ディープラーニングのベースとなっている数学的理論の部分をゼロから開発せずとも、比較的**短い**ソースコードで実装することができます。"]},{"cell_type":"markdown","metadata":{"id":"zxHr8M5Uz_bt"},"source":["## 本日実現したいこと (作成する人工知能の能力)\n","今回利用する MNIST のデータは、(1)次のような手書きの 0 〜 9 の数字が書かれた画像データ と、(2)その画像に書かれた実際の数字データ のペアです。\n","\n","<img src =　https://weblabo.oscasierra.net/wp-content/uploads/2017/08/python-ai-mnist-data-detail-1.png alt = sample>\n","\n","### **入力データ**\n","前述の通り、入力データは1つの数字が書かれた画像データです。 MNISTの画像1つは 28×28 ピクセル(＝784ピクセル)の大きさです。 1ピクセルごとに「白」〜「黒」までの色情報が記録されています。 1つの画像の全てのピクセルの情報を人工知能の入力としますので、入力の数は784個になります。\n","\n","### **出力データ**\n","画像データを入力された人工知能は、どの数字の画像なのかを考えたあとに、「0」〜「9」までの数字毎にその確率を出力します。 例えば次の表のようなイメージです。 次の表の例だと「3」の確率が一番高いので、人工知能が「3」だと判断したことになります。 このように数字ごとに確率を出力するので、出力の数は10個になります。\n","\n","<table>\n","<thead><tr>\n","<th style=\"text-align:left\">数字</th>\n","<th style=\"text-align:left\">確率</th>\n","</tr>\n","</thead>\n","<tbody>\n","<tr>\n","<td style=\"text-align:left\">0</td>\n","<td style=\"text-align:left\">0.014</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">1</td>\n","<td style=\"text-align:left\">0.001</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">2</td>\n","<td style=\"text-align:left\">0.013</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">3</td>\n","<td style=\"text-align:left\">0.719</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">4</td>\n","<td style=\"text-align:left\">0.034</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">5</td>\n","<td style=\"text-align:left\">0.016</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">6</td>\n","<td style=\"text-align:left\">0.023</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">7</td>\n","<td style=\"text-align:left\">0.065</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">8</td>\n","<td style=\"text-align:left\">0.086</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">9</td>\n","<td style=\"text-align:left\">0.029</td>\n","</tr>\n","</tbody>\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"y8-DtOLk9NpX"},"source":["## 1.CSVファイルの作成\n","\n","モデルの学習結果を保存しておけるCSVファイルを作成します。後に学習結果をグラフで描画する際に活用します。\n","（この手順は任意です。変数に代入してメモリ上に保持しておくこともできます。）\n"]},{"cell_type":"code","metadata":{"id":"JHTcUu99YruE"},"source":["import os\n","import pathlib                            #ファイル操作が得意なpathlibモジュールのインポート\n","\n","CSV_FILE_PATH = \"trainlog.csv\"            #モデルのトレーニング結果を載せるcsvファイルの設定\n","\n","if not os.path.exists(CSV_FILE_PATH):     #ファイルが存在しないなら\n","    pathlib.Path(CSV_FILE_PATH).touch()   #ファイル作成"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMBFVTaT3e6A"},"source":["## 2.データの読み込み\n","\n","Tensorflowから実行環境(このファイル)へMNIST Datasetを読み込みましょう．\n","TensorflowはGoogleが開発したオープンソース機械学習プラットフォームです。"]},{"cell_type":"code","metadata":{"id":"v7uktLmZYrww"},"source":["import tensorflow as tf\n","\n","#tensorflowのKerasからMNISTデータの取得\n","mnist = tf.keras.datasets.mnist\n","\n","#　MNISTデータからトレーニング用データとテスト用データ作成\n","(X_train, y_train),(X_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQjpiOwqBryx"},"source":["MNISTデータは、次の4つのファイルで構成されています。\n","\n","t10k-images-idx3-ubyte.gz:検証用の画像セット\n","\n","\n","t10k-labels-idx1-ubyte.gz:検証用のラベルセット\n","\n","\n","train-images-idx3-ubyte.gz:学習用の画像セット\n","\n","\n","train-labels-idx1-ubyte.gz:学習用のラベルセット"]},{"cell_type":"markdown","metadata":{"id":"dq4zc8x2_TFj"},"source":["## 3.メモリ節約（小技）\n","\n","MNISTの生データが入っているmnist変数はもう不要なのでメモリから完全に削除しましょう"]},{"cell_type":"code","metadata":{"id":"lQguXX9y_i_-"},"source":["del mnist          #不要な変数mnistを削除\n","\n","\n","#以下の操作はpythonでは自動的に行ってくれるが、今回は明示的に行ってみる\n","import gc          #gcモジュールをインポート\n","gc.collect()       #不要になったメモリ領域を解放して再利用可能にする"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"REURtvs2HhOC"},"source":["## 4.MNIST Datasetのサンプルデータを見てみる\n","\n","\n","データセットの型はnumpy.ndarrayです。\n","\n","最初にshape関数で配列の形状を取得して確認してみましょう\n","\n","中身は学習用データは数字の画像6万枚分、検証用データは１万枚分のデータとなっていて、\n","さらに画像データは28x28ピクセルで一つの数字を表しているのでその内容が反映された結果となるはずです。"]},{"cell_type":"code","metadata":{"id":"xmFqiBbfYrzd"},"source":["print(\"X_train : \", X_train.shape)\n","print(\"y_train : \", y_train.shape)\n","print(\"X_test : \", X_test.shape)\n","print(\"y_test : \", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0mL-TpyIedT"},"source":["次に実際に学習用データの\n","X(白黒画像)とy(ラベル)を視覚的に確認してみましょう\n","\n","（検証用データも同様な中身になっています）"]},{"cell_type":"code","metadata":{"id":"X5PmuTelYr2d"},"source":["import matplotlib\n","import matplotlib.pyplot as plt                      #画像描画用のライブラリにmatplotlibを使います。\n","%matplotlib inline\n","\n","#1, 10, 100番目のデータ　について確認したい\n","for i in [1,10,100]:\n","    print(\"y_train\", \"(i=\"+str(i)+\"): \", y_train[i])     #　i番目のラベル表示\n","    print(\"X_train\", \"(i=\"+str(i)+\"): \")\n","    plt.imshow(X_train[i], cmap='gray')              #matplotliibを使いグレースケールで数字の画像表示\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CayfVWVDbflZ"},"source":["## 5.画像データの正規化\n","全ての特徴の大きさを同じレベルで扱うために、学習モデルを構築する前の前処理としてデータを正規化（０〜１の大きさに限定）する必要があります。\n","\n","代表的な正規化手法としては以下2つが挙げられます．\n","\n","### **min-max normalization**\n","最小値が0, 最大値が1になるように変換する\n","\n","\n","x_new = (x - x_min) / (x_max - x_min)\n","\n","\n","### **z-score normalization**\n","\n","\n","平均が0, 標準偏差が1になるよう変換する\n","\n","\n","x_new = (x - x_mean) / x_std\n","\n","---------------------------------------------------\n","\n","↓で確認できるように、MNIST Datasetに含まれる画像データでは，各画素の値が「0以上255以下」の8bit整数で表現されています．"]},{"cell_type":"code","metadata":{"id":"jURmcE5BYr5C"},"source":["print(\"X_train min\", X_train.min())\n","print(\"X_train max\", X_train.max())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-EB4xZjucE3Q"},"source":["今回は，これにmin-max normalizationを適用することで，値の範囲を「0~1」に限定させます．"]},{"cell_type":"code","metadata":{"id":"xmmAZlGJY39C"},"source":["# Min-Max Normalization\n","X_train, X_test = X_train/255.0, X_test/255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w3c0z_Cxc3No"},"source":["上手く正規化できたか確認します"]},{"cell_type":"code","metadata":{"id":"MrsL9q6zY3_b"},"source":["print(\"X_train min\", X_train.min())\n","print(\"X_train max\", X_train.max())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oW2q4l22w48l"},"source":["## 6.CNNモデルの作成"]},{"cell_type":"markdown","metadata":{"id":"YXZO0ztoUMro"},"source":["\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2019-03-07-8.56.07.jpg\" alt = \"filter\" height = \"250px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","CNN（畳み込みニューラルネットワーク）では、\n","\n","\n","1. 畳み込みフィルタ層：画像の濃淡パターンを検出します。（エッジ抽出等の特徴抽出）\n","\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/3cnn.gif\" alt = \"filter\" height = \"400px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","2. プーリング層：物体の位置が変動しても同一の物体であると見なせるようにします。（位置ズレを許容する）また，プーリングには，「maxプーリング」と「avgプーリング」の2種類があります．\n","\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/pooling.gif\" alt = \"filter\" height = \"200px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","　これらの層を組み合わせることによって、画像から特徴量を抽出する働きを担っています。\n","\n","\n","　一方、特徴量を抽出するだけでは、画像の識別はできません。識別には、「特徴量に基づいた分類」が必要です。この分類の役割を担っているのが、全結合層と出力層です。\n","\n","\n","3. 全結合層：①②を通して特徴部分が取り出された画像データを一つのノードに結合し、活性化関数（後述）によって変換された値（特徴変数）を出力します。ノードの数が増えると特徴量空間の分割数が増し、各領域を特徴付ける特徴変数の数が増えます。\n","\n","4. 出力層：全結合層からの出力（特徴変数）を元に、ソフトマックス関数を用いて確率に変換し、それぞれの領域に正しく分類される確率を最大化する（最尤推定法）ことによって分類を行います。\n","\n"]},{"cell_type":"code","metadata":{"id":"z07hUzA0Y4CS"},"source":["model = tf.keras.models.Sequential([\n","    # (None, 28, 28) -> (None, 784)\n","    tf.keras.layers.Flatten(input_shape=(28, 28), name='input'),\n","    \n","    # Layer1: 線形写像（一次変換）: (None, 784) -> (None, 512)\n","    tf.keras.layers.Dense(512, name='fc_1'),\n","    # 活性化関数: ReLU　　（活性化関数とは入力のなんらかの合計（しばしば、線形な重み付け総和）から、出力を決定するための関数）\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_1'),\n","    \n","    # Layer2: 線形写像（一次変換）: (None, 512) -> (None, 256)\n","    tf.keras.layers.Dense(256, name='fc_2'),\n","    # 活性化関数: ReLU\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_2'),\n","    \n","    # Layer3: 線形写像（一次変換）: (None, 256) -> (None, 256)\n","    tf.keras.layers.Dense(256, name='fc_3'),\n","    # 活性化関数: ReLU\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_3'),\n","    \n","    # Layer4: 線形写像（一次変換）: (None, 256) -> (None, 10)\n","    tf.keras.layers.Dense(10, name='dense_3'),\n","    # 活性化関数: Softmax\n","    tf.keras.layers.Activation(tf.nn.softmax, name='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvKyUZLXY4Et"},"source":["# 作成したモデルの構造を確認します\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"psWaHThmbAmW"},"source":["## 7.コンパイル\n","\n","モデルを使った学習の前に、どのような学習処理を行うかをcompileメソッドを用いて設定します。\n"]},{"cell_type":"code","metadata":{"id":"dgzYfwm0Y4HW"},"source":["# モデルと学習の情報をメモリにセット (CPU or GPU)\n","model.compile(optimizer='adam',                         #最適化アルゴリズム。adamは定番\n","              loss='sparse_categorical_crossentropy',   #ズレの大きさを定量化する損失関数\n","              metrics=['accuracy'])                     #訓練やテストの際にモデルを評価するための評価関数のリスト"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BiB560QGglHt"},"source":["＊損失とはニューラルネットワークによる予測値と正解値との**ズレ**のことです。そのため、ニューラルネットワークの予測値が変われば、損失も変わります。そのニューラルネットワークの予測値はパラメータ(重みおよびバイアス)で変化します。損失は小さいほどいいです"]},{"cell_type":"markdown","metadata":{"id":"wctqCia3f61O"},"source":["## 8.寄り道-コールバック関数の設定\n","\n","モデルの学習途中記録を可視化するためにコールバック関数（トレーニング中にコールされる）を設定します。"]},{"cell_type":"code","metadata":{"id":"BxdzG0tRZFpq"},"source":["callbacks = []\n","callbacks.append(tf.keras.callbacks.CSVLogger(CSV_FILE_PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HuvsLvjz9yg2"},"source":["## 9.モデルの学習"]},{"cell_type":"code","metadata":{"id":"bio_ZASaZFsd"},"source":["history = model.fit(X_train, y_train,  #学習様データを使いながら、KerasライブラリのModelクラスのfit関数で学習します\n","                    batch_size=100,  #　データを１００個ずつに分ける。データサイズは６００００なので全部で６００回の学習になる\n","                    epochs=30, #　学習反復回数\n","                    verbose=1,  #ログの詳細表示オプション。1の場合はログをプログレスバーで標準出力\n","                    validation_data=(X_test, y_test), #検証データで検証（今回はテストデータで検証してます）\n","                    callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaZz5_XqkweG"},"source":["## 10.学習済みモデルの評価\n","学習済みモデル(model)のtestデータ(X_test,y_test)に対するの正答率(accuracy)と損失関数の値(loss)を確認します。"]},{"cell_type":"code","metadata":{"id":"ARTABf1GZSU6"},"source":["train_loss, train_acc = model.evaluate(X_train, y_train, verbose=1)\n","print(\"loss(train): {:.4}\".format(train_loss))\n","print(\"accuracy(train): {:.4}\".format(train_acc))\n","\n","print()\n","\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n","print(\"loss(test): {:.4}\".format(test_loss))\n","print(\"accuracy(test): {:.4}\".format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpmcYoTTlAfj"},"source":["用意しておいたCSVファイルを元に，学習曲線(モデルに対する評価指標の経過を表す)を描画してみます。まずは中身を確認します。"]},{"cell_type":"code","metadata":{"id":"Ks5OT6kIbRZf"},"source":["import pandas as pd \n","df = pd.read_csv(CSV_FILE_PATH)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kcv44zhjq6pZ"},"source":["グラフ描画に使う変数を設定します"]},{"cell_type":"code","metadata":{"id":"d-G3iKBGZSYF"},"source":["epochs = df[\"epoch\"].values\n","train_acc = df[\"accuracy\"].values\n","train_loss = df[\"loss\"].values\n","test_acc = df[\"val_accuracy\"].values\n","test_loss = df[\"val_loss\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HEA-bdqVlRG0"},"source":["###**損失関数の値**"]},{"cell_type":"code","metadata":{"id":"YNrSccLpZFwi"},"source":["plt.plot(epochs, train_loss, label=\"train data\")#　x座標データ　y座標データ　ラベル\n","plt.plot(epochs, test_loss, label=\"test data\")\n","plt.xlabel(\"epochs\")#　x軸ラベル\n","plt.ylabel(\"loss\\n(categorical crossentropy)\")#　y軸ラベル\n","plt.legend(loc=\"upper right\")#　右上に凡例\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSr7McQXlXAM"},"source":["###**画像分類の正答率**\n","\n","学習用データの曲線は、1.00にかなり近いところまでいってます。\n","検証用データ（今回はテストデータ）の曲線との差はグラフからはかなりあるように見えますが、0.02(2%)程度です。"]},{"cell_type":"code","metadata":{"id":"3o48HN2mZX8o"},"source":["plt.plot(epochs, train_acc, label=\"train data\")\n","plt.plot(epochs, test_acc, label=\"test data\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q28Cd8z0wtmm"},"source":["因みに学習用データを60000→600に減らすと、局所解に陥り検証データの曲線の精度が１０％以上落ちます。"]},{"cell_type":"markdown","metadata":{"id":"lsQ87co6lfLE"},"source":["## 11.学習済みモデルによる推論計算\n","学習済みモデルを用いて，testデータに対する推論計算を行い，分類結果を見てみます。"]},{"cell_type":"code","metadata":{"id":"O14yoyk3ZYEQ"},"source":[" for i in [0,1,2]:\n","    y_true = y_test[i]\n","    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n","    print(\"モデルによる予測\", \"(i=\"+str(i)+\"): \", y_pred)\n","    print(\"学習済みモデルに流す画像データのラベル\", \"(i=\"+str(i)+\"): \", y_true)\n","    print(\"学習済みモデルに流す画像データ\", \"(i=\"+str(i)+\"): \")\n","    plt.imshow(X_test[i], cmap='gray')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHahjMvAZcer"},"source":["fig = plt.figure(figsize=(12, 8))\n","\n","ROW = 4\n","COLUMN = 5\n","\n","for i in range(ROW * COLUMN):\n","    y_true = y_test[i]\n","    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n","    \n","    if y_true == y_pred:\n","        result = \"True\" # 正解\n","    else:\n","        result = \"False\" # ハズレ\n","    \n","    plt.subplot(ROW, COLUMN, i+1)\n","    plt.imshow(X_test[i], cmap='gray')\n","    plt.title(\"No.{} - {}\\ny_true:{}, y_pred:{}\".format(i, result, y_true, y_pred))\n","    plt.axis(\"off\")\n","\n","fig.tight_layout()\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jrAONdkIlzsz"},"source":["## 12.学習済みモデルの保存\n","Kerasでは，全てのニューラルネットワークモデルがkeras.models.Model()クラスのインスタンスとなっています．学習済みモデルmodelに対して， model.save()を実行することで「モデルの保存」が完了します．"]},{"cell_type":"code","metadata":{"id":"7gj8ZeZ2ZciV"},"source":["ins_path = 'trained_model_v0.h5'\n","model.save(ins_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVNkN5jMhLUe"},"source":["##（発展）ディープラーニング  転移学習"]},{"cell_type":"markdown","metadata":{"id":"Th9oU1g8mG3j"},"source":["転移学習(Transfer Learning)とは、ある領域で学習したこと(学習済みモデル)を別の領域に役立たせ、効率的に学習させる方法です。\n","\n","<img src = \"https://s3-ap-northeast-1.amazonaws.com/ledge-assets/media/wp-content/uploads/2020/05/08173933/fig1.png\" alt = \"filter\" height = \"250px\">\n","出典：https://ledge.ai/transfer-learning/\n","\n","**実用例：Survival Prediction**\n","\n","参考：Transfer learning with convolutional neural networks for cancer survival prediction using gene-expression data（Guillermo López-García, José M. Jerez, Leonardo Franco, Francisco J. Veredas）\n","\n","https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230536\n","\n","肺癌を除く３１種類の異なる癌について、ゲノム配列と患者の生存率データを使って**予め学習した**CNNモデルを用意します。\n","肺癌のRNAシーケンスデータを使ってそのCNNモデルをファインチューニング（学習済みモデルの最終出力層を付け替え、入力層に近い部分と出力層のパラメータも変更する）します。\n","\n","\n","結果として、ゲノム配列を学習する際のCNNの弱点（隣接する塩基の関連性が見出しづらい等）を克服し、他の機械学習手法（MLNNsや他のML手法）よりも高パフォーマンスな予測ができたという報告がありました。"]},{"cell_type":"markdown","metadata":{"id":"G4E0lR8bhOe-"},"source":["##（おまけ）ディープラーニング   深層強化学習"]},{"cell_type":"markdown","metadata":{"id":"qjFINpqjj_0G"},"source":["**特徴**\n","\n","1. 教師データが無くても学習できる（環境に対する試行錯誤によってターゲットをサンプリングできる）\n","\n","1. 未知の環境に対しても学習できる\n","\n","\n","**例**\n","\n","  深層強化学習を使ったゲーム攻略\n","\n","https://qiita.com/yukiB/items/0a3faa759ca5561e12f8\n","\n","<img src = \"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F59864%2F6dcd9255-4f66-c606-23fd-d0002087ae80.gif?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&w=1400&fit=max&s=8e83c2114104c6626db0d67bfa2d12a0\" alt = \"filter\" height = \"250px\">\n","<img src = \"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F59864%2F78af77ed-882b-72c1-983b-1ba0036cb048.gif?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&w=1400&fit=max&s=b86f47064a104c8111f794aafe701a6d\" alt = \"filter\" height = \"250px\">"]}]}