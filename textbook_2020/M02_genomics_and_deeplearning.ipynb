{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M02_genomics_and_deeplearning.ipynb","provenance":[],"collapsed_sections":["oezBiM7Lj3dK","D2EmRvhEj64d","0lkkqR1Yk4A9","Svsw91FKk6EN"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QvU3P1MljiqF"},"source":["# データ解析体験(2) - ゲノム解析とディープラーニング -\n","\n","\n","\n","**ディープラーニング（深層学習; Deep Learning）**は、いまでは実社会の様々なところで使われています（例えば、Googleフォトの画像認識、スマホの音声認識アプリなど）。生物学データ解析やゲノム解析でも使われるようになってきています。今回は、そのディープラーニングをおこないます。\n","\n","<small>※ やや難しく感じるコードが出てくるかもしれませんが、習っていないことを所々に含んでいるだけです。勉強すれば自分で同じようなプログラムを書けるようになります。Pythonプログラミングを勉強した先にできることのひとつとして、今回ディープラーニングを体験してください。</small>\n"]},{"cell_type":"markdown","metadata":{"id":"oezBiM7Lj3dK"},"source":["## **ディープラーニングとニューラルネットワーク**"]},{"cell_type":"markdown","metadata":{"id":"x5-hGJMo81nf"},"source":["\n","**ニューロン**\n","\n","<img src = \"https://upload.wikimedia.org/wikipedia/en/3/3e/Neuron-no_labels2.png\" alt = \"filter\" height = \"150px\">\n","\n","<small>画像は　https://en.wikipedia.org/wiki/File:Neuron-no_labels2.png　から引用</small>\n","\n","****\n","\n","**ニューラルネットワークのニューロン**\n","\n","ニューラルネットワークを構成するニューロンは生物のニューロンとかなり類似しています。\n","下の画像が示す様な計算にしたがって情報を伝達するのですが、人間の脳神経でも似た原理で情報伝達（学習）が行われるのではないかと考えられています。\n","\n","<img src = \"https://newtechnologylifestyle.net/wp-content/uploads/2018/02/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0.png\" alt = \"filter\" height = \"250px\">\n","\n","<small>画像はhttps://newtechnologylifestyle.net から引用</small>\n","\n","＊重み・・・入力値の重要性を決定する値\n","\n","＊バイアス・・・入力値を一定の範囲に偏らせるのに必要な値\n","\n","＊活性化関数・・・重みとバイアスを考慮した入力情報の合計を引数とし、ニューロンが『発火』するかどうか決定します。（生体のニューロンの活動電位発生による活性化を思い出すとわかりやすいです）\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"D2EmRvhEj64d"},"source":["## **ゲノム解析にディープラーニングを用いる例**\n","\n","画像および解析内容の出典：7. 実践編: ディープラーニングを使った配列解析\n","\n","https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/07_DNA_Sequence_Data_Analysis.html"]},{"cell_type":"markdown","metadata":{"id":"VqlltCJZYh8m"},"source":["\n","\n","**概要**\n","\n","数百種類の人の細胞型から得られた数千のChIP-seq，DNase-seq（オープンクロマチン領域の網羅的解析の一手法）のデータセットから得られたDNA塩基配列を入力として，CAGE（正確性、定量性に優れたRNAシーケンス手法）の結果計測されたmRNAの発現量を推定する問題を考えます。\n","\n","**扱うデータ**\n","\n","****\n","<<学習用>>\n","\n","長さが130172bpの配列が5000個あり、それぞれA, T, C, Gの対応する次元の値が1, それ以外は0であるような配列\n","\n","train_in (5000, 131072, 4)\n","\n","長さが1024bpからなる配列が5000個あり,それぞれが10種類の異なるChIP-seqの結果のカバレッジ値\n","\n","train_out (5000, 1024, 10)\n","\n","****\n","\n","<<検証用>>\n","\n","\n","valid_in (500, 131072, 4)\n","\n","valid_out (500, 1024, 10)\n","\n","****\n","\n","<<テスト用>>\n","\n","\n","test_in (500, 131072, 4)\n","\n","test_out (500, 1024, 10)\n","\n","****\n","\n","\n","**モデルとモデルの学習**\n","\n","モデルには配列データを1次元の画像とみなし，画像処理の時と同様な解析を行えるCNN（畳み込みニューラルネットワーク）をモデルとして使います。\n","\n","\n","\n","さらに、ゲノム配列の情報は長いので、少ない層で学習する為にCNNの中でもDilated Convolution　というモデルを学習すべきニューラルネットワークとして採用します。\n","\n","↓の画像はDilated Convolutionのごく簡単な模式図で、Hidden Layerには先ほど紹介したニューロンの計算を行う層も存在します。\n","\n","<img src = \"https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif\" alt = \"filter\" height = \"250px\">\n","\n","\n","〜この後の流れ〜\n","\n","**学習用データと検証用データでニューラルネットワークの学習**\n","\n","（参考元では**Chainer**ライブラリを使ってディープラーニングを行っています）\n","\n","**テストデータに対して学習済みのモデルを適用**\n","\n","↓はテストデータを使った検証結果の一部です。ピークをきちんと捉えており、配列データを使ってmRNAの発現量を推定することができたようです。\n","\n","<img src = \"https://japan-medical-ai.github.io/medical-ai-course-materials/_images/notebooks_07_DNA_Sequence_Data_Analysis_43_1.png\" alt = \"filter\" height = \"400px\">\n"]},{"cell_type":"markdown","metadata":{"id":"6BPFULUCyRqK"},"source":["---\n","## **Keras/Tensorflow　で手書き文字の画像分類**\n"]},{"cell_type":"markdown","metadata":{"id":"zxHr8M5Uz_bt"},"source":["## 本日実現したいこと (作成する人工知能の能力)\n","\n","MNISTは手書きの数字を白黒画像にしたデータです。\n"," ここでは人工知能ライブラリ Keras で MNIST（手書き数字１〜９の白黒画像）の画像データを学習させ、画像に書かれている数字１〜９を識別できるような**人工知能**を作ります。\n","\n","＊Kerasは手軽で柔軟性があるため、現在最も多く利用されている人工知能ライブラリです。"]},{"cell_type":"markdown","metadata":{"id":"-dz8Pf8a1Lck"},"source":["### **入力データ**\n","入力データは1つの数字が書かれた画像データの集合です。 \n","\n","**↓画像一つに含まれるデータ**\n","\n","・28×28 ピクセル(＝784ピクセル) \n","\n","・1ピクセルごとに「白」〜「黒」までの色情報\n","\n","なので1つの画像当たり、入力の数は784個になります。\n"]},{"cell_type":"markdown","metadata":{"id":"scyo22bw2bUG"},"source":["### **出力データ**\n","\n","・「0」〜「9」までの数字毎の確率\n","\n","・出力の数は10個\n","\n","例えば↓の表の様に、１０個の各数字について確率を出力し、表では３の確率が一番高いため入力画像に書かれている数字は『３』であるとわかります。\n","\n","<table>\n","<thead><tr>\n","<th style=\"text-align:left\">数字</th>\n","<th style=\"text-align:left\">確率</th>\n","</tr>\n","</thead>\n","<tbody>\n","<tr>\n","<td style=\"text-align:left\">0</td>\n","<td style=\"text-align:left\">0.014</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">1</td>\n","<td style=\"text-align:left\">0.001</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">2</td>\n","<td style=\"text-align:left\">0.013</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">3</td>\n","<td style=\"text-align:left\">0.719</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">4</td>\n","<td style=\"text-align:left\">0.034</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">5</td>\n","<td style=\"text-align:left\">0.016</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">6</td>\n","<td style=\"text-align:left\">0.023</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">7</td>\n","<td style=\"text-align:left\">0.065</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">8</td>\n","<td style=\"text-align:left\">0.086</td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\">9</td>\n","<td style=\"text-align:left\">0.029</td>\n","</tr>\n","</tbody>\n","</table>"]},{"cell_type":"code","metadata":{"id":"QOfkisDQYj36"},"source":["#後々利用するのでnumpy(数値計算を効率よく行うためのライブラリ）を先んじてimportしておきます。\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8-DtOLk9NpX"},"source":["## 1.CSVファイルの作成\n","\n","モデルの学習結果を保存しておけるCSVファイルを作成します。後に学習結果をグラフで描画する際に活用します。\n","（この手順は任意です。変数に代入してメモリ上に保持しておくこともできます。）\n"]},{"cell_type":"code","metadata":{"id":"JHTcUu99YruE"},"source":["import os\n","import pathlib                            #ファイル操作が得意なpathlibモジュールのインポート\n","\n","CSV_FILE_PATH = \"trainlog.csv\"            #モデルのトレーニング結果を載せるcsvファイルの設定\n","\n","if not os.path.exists(CSV_FILE_PATH):     #ファイルが存在しないなら\n","    pathlib.Path(CSV_FILE_PATH).touch()   #ファイル作成"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMBFVTaT3e6A"},"source":["## 2.データの読み込み\n","\n","Tensorflowから実行環境(このGoogle Colabのフォルダ)へMNIST Datasetを読み込みます。\n","TensorflowはGoogleが開発したオープンソース機械学習プラットフォームです。"]},{"cell_type":"code","metadata":{"id":"v7uktLmZYrww"},"source":["import tensorflow as tf\n","\n","#tensorflowのKerasからMNISTデータの取得\n","mnist = tf.keras.datasets.mnist\n","\n","#　MNISTデータからトレーニング用データとテスト用データ作成\n","(X_train, y_train),(X_test, y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQjpiOwqBryx"},"source":["MNISTデータは、次の4つのファイルで構成されています。\n","\n","t10k-images-idx3-ubyte.gz:検証用の画像セット\n","\n","\n","t10k-labels-idx1-ubyte.gz:検証用のラベルセット\n","\n","\n","train-images-idx3-ubyte.gz:学習用の画像セット\n","\n","\n","train-labels-idx1-ubyte.gz:学習用のラベルセット"]},{"cell_type":"markdown","metadata":{"id":"dq4zc8x2_TFj"},"source":["## 3.メモリ節約（小技）\n","\n","MNISTの生データが入っているmnist変数はもう不要なのでメモリから完全に削除しましょう"]},{"cell_type":"code","metadata":{"id":"lQguXX9y_i_-"},"source":["del mnist          #不要な変数mnistを削除\n","\n","\n","#以下の操作はpythonでは自動的に行ってくれるが、今回は明示的に行ってみる\n","import gc          #gcモジュールをインポート\n","gc.collect()       #不要になったメモリ領域を解放して再利用可能にする"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"REURtvs2HhOC"},"source":["## 4.MNIST Datasetのサンプルデータを見てみる\n","\n","\n","データセットの型はnumpy.ndarrayです。\n","\n","最初にshape関数で配列の形状を取得して確認してみましょう\n","\n","中身は学習用データは数字の画像6万枚分、検証用データは１万枚分のデータとなっていて、\n","さらに画像データは28x28ピクセルで一つの数字を表しているのでその内容が反映された結果となるはずです。"]},{"cell_type":"code","metadata":{"id":"xmFqiBbfYrzd"},"source":["print(\"X_train : \", X_train.shape)\n","print(\"y_train : \", y_train.shape)\n","print(\"X_test : \", X_test.shape)\n","print(\"y_test : \", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0mL-TpyIedT"},"source":["次に実際に学習用データの\n","X(白黒画像)とy(ラベル)を視覚的に確認してみましょう\n","\n","（検証用データも同様な中身になっています）"]},{"cell_type":"code","metadata":{"id":"X5PmuTelYr2d"},"source":["import matplotlib\n","import matplotlib.pyplot as plt                      #画像描画用のライブラリにmatplotlibを使います。\n","%matplotlib inline\n","\n","#1, 10, 100番目のデータ　について確認したい\n","for i in [1,10,100]:\n","    print(\"y_train\", \"(i=\"+str(i)+\"): \", y_train[i])     #　i番目のラベル表示\n","    print(\"X_train\", \"(i=\"+str(i)+\"): \")\n","    plt.imshow(X_train[i], cmap='gray')              #matplotliibを使いグレースケールで数字の画像表示\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CayfVWVDbflZ"},"source":["##5.画像データの正規化\n","全ての特徴の大きさを同じレベルで扱うために、学習モデルを構築する前の前処理としてデータを正規化（０〜１の大きさに限定）する必要があります。\n","\n","代表的な正規化手法としては以下2つが挙げられます．\n","\n","### **min-max normalization**\n","最小値が0, 最大値が1になるように変換する\n","\n","\n","x_new = (x - x_min) / (x_max - x_min)\n","\n","\n","### **z-score normalization**\n","\n","\n","平均が0, 標準偏差が1になるよう変換する\n","\n","\n","x_new = (x - x_mean) / x_std\n","\n","---------------------------------------------------\n","\n","↓で確認できるように、MNIST Datasetに含まれる画像データでは，各画素の値が「0以上255以下」の8bit整数で表現されています．"]},{"cell_type":"code","metadata":{"id":"jURmcE5BYr5C"},"source":["print(\"X_train min\", X_train.min())\n","print(\"X_train max\", X_train.max())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-EB4xZjucE3Q"},"source":["今回は，これにmin-max normalizationを適用することで，値の範囲を「0~1」に限定させます．"]},{"cell_type":"code","metadata":{"id":"xmmAZlGJY39C"},"source":["# Min-Max Normalization\n","X_train, X_test = X_train/255.0, X_test/255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w3c0z_Cxc3No"},"source":["上手く正規化できたか確認します"]},{"cell_type":"code","metadata":{"id":"MrsL9q6zY3_b"},"source":["print(\"X_train min\", X_train.min())\n","print(\"X_train max\", X_train.max())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oW2q4l22w48l"},"source":["## 6.CNNモデルの作成\n","\n","モデルを作成する前に今回採用するCNN（畳み込みニューラルネットワーク）について、細かく見ていきます。"]},{"cell_type":"markdown","metadata":{"id":"YXZO0ztoUMro"},"source":["\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2019-03-07-8.56.07.jpg\" alt = \"filter\" height = \"250px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","Kerasを使った畳み込みニューラルネットワークの構築では、様々な層から自分の好きな種類、順序、回数を決めて積み立てられます。\n","\n","↓ではカラー画像分類を念頭に置いた時の各層の簡単な説明が書いてあります。\n","\n","1. 畳み込みフィルタ層：入力データから画像の濃淡パターン（特徴量）取り出します。\n","\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/3cnn.gif\" alt = \"filter\" height = \"400px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","2. プーリング層：特徴量を圧縮します。また、物体の位置が変動しても同一の物体であると見なせるようにします。（位置ズレを許容する）また，プーリングには，「maxプーリング」と「avgプーリング」の2種類があります．\n","\n","<img src = \"https://kenyu-life.com/wp-content/uploads/2019/03/pooling.gif\" alt = \"filter\" height = \"200px\">\n","\n","<small>画像は[kenyu-life.com](https://kenyu-life.com/2019/03/07/convolutional_neural_network/) から引用 </small>\n","\n","　これらの層を組み合わせることによって、画像から特徴量を抽出することができます。\n","\n","3. 全結合層：最初のニューロンの説明にあった様に、入力データに対して重みを乗算しバイアス加算したものに変換します。\n","\n","4. 出力層：全結合層からの出力データを元に、ソフトマックス関数を用いて確率に変換し、それぞれの領域に正しく分類される確率を最大化する（最尤推定法）ことによって分類を行います。\n","\n"]},{"cell_type":"code","metadata":{"id":"z07hUzA0Y4CS"},"source":["#28(ピクセル）x28（ピクセル）x1(色なし)=784個の入力数から10個の出力数を目指して層を重ねます\n","#モデルはCNNのSequentialという形式で、色々な層が使えますがここでは簡略のため基本的な全結合層ばかり使ってます。\n","\n","model = tf.keras.models.Sequential([\n","    # 二次元のデータを1次元にします(None, 28, 28) -> (None, 784)\n","    tf.keras.layers.Flatten(input_shape=(28, 28), name='input'),\n","    \n","    # 全結合層: (None, 784) -> (None, 512)\n","    tf.keras.layers.Dense(512, name='fc_1'),\n","    # 活性化関数: ReLU　　（活性化関数とは入力のなんらかの合計（しばしば、線形な重み付け総和）から、出力を決定するための関数）\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_1'),\n","    \n","    # 全結合層: (None, 512) -> (None, 256)\n","    tf.keras.layers.Dense(256, name='fc_2'),\n","    # 活性化関数: ReLU\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_2'),\n","    \n","    # 全結合層: (None, 256) -> (None, 256)\n","    tf.keras.layers.Dense(256, name='fc_3'),\n","    # 活性化関数: ReLU\n","    tf.keras.layers.Activation(tf.nn.relu, name='relu_3'),\n","    \n","    # 全結合層: (None, 256) -> (None, 10)\n","    tf.keras.layers.Dense(10, name='dense_3'),\n","    # 出力層:　活性化関数: Softmax\n","    tf.keras.layers.Activation(tf.nn.softmax, name='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvKyUZLXY4Et"},"source":["# 作成したモデルの構造を確認します\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"psWaHThmbAmW"},"source":["## 7.コンパイル\n","\n","モデルを使った学習の前に、どのような学習処理を行うかをcompileメソッドを用いて設定します。\n"]},{"cell_type":"code","metadata":{"id":"dgzYfwm0Y4HW"},"source":["# モデルと学習の情報をメモリにセット (CPU or GPU)\n","model.compile(optimizer='adam',                         #最適化アルゴリズム。adamは定番\n","              loss='sparse_categorical_crossentropy',   #ズレの大きさを定量化する損失関数\n","              metrics=['accuracy'])                     #訓練やテストの際にモデルを評価するための評価関数のリスト"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BiB560QGglHt"},"source":["＊損失とはニューラルネットワークによる予測値と正解値との**ズレ**のことです。そのため、ニューラルネットワークの予測値が変われば、損失も変わります。そのニューラルネットワークの予測値はパラメータ(重みおよびバイアス)で変化します。損失は小さいほどいいです。"]},{"cell_type":"markdown","metadata":{"id":"wctqCia3f61O"},"source":["## 8.寄り道-コールバック関数の設定\n","\n","モデルの学習途中記録を可視化するためにコールバック関数（トレーニング中にコールされる）を設定します。"]},{"cell_type":"code","metadata":{"id":"BxdzG0tRZFpq"},"source":["callbacks = []\n","callbacks.append(tf.keras.callbacks.CSVLogger(CSV_FILE_PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HuvsLvjz9yg2"},"source":["## 9.モデルの学習"]},{"cell_type":"code","metadata":{"id":"bio_ZASaZFsd"},"source":["history = model.fit(X_train, y_train,  #学習様データを使いながら、KerasライブラリのModelクラスのfit関数で学習します\n","                    batch_size=100,  #　データを１００個ずつに分ける。データサイズは６００００なので全部で６００回の学習になる\n","                    epochs=30, #　学習反復回数\n","                    verbose=1,  #ログの詳細表示オプション。1の場合はログをプログレスバーで標準出力\n","                    validation_data=(X_test, y_test), #検証データで検証（今回はテストデータで検証してます）\n","                    callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaZz5_XqkweG"},"source":["##10. 学習済みモデルの評価\n","学習済みモデル(model)のtestデータ(X_test,y_test)に対するの正答率(accuracy)と損失関数の値(loss)を確認します。"]},{"cell_type":"code","metadata":{"id":"ARTABf1GZSU6"},"source":["train_loss, train_acc = model.evaluate(X_train, y_train, verbose=1)\n","print(\"loss(train): {:.4}\".format(train_loss))\n","print(\"accuracy(train): {:.4}\".format(train_acc))\n","\n","print()\n","\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n","print(\"loss(test): {:.4}\".format(test_loss))\n","print(\"accuracy(test): {:.4}\".format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpmcYoTTlAfj"},"source":["用意しておいたCSVファイルを元に，学習曲線(モデルに対する評価指標の経過を表す)を描画してみます。まずは中身を確認します。"]},{"cell_type":"code","metadata":{"id":"Ks5OT6kIbRZf"},"source":["import pandas as pd \n","df = pd.read_csv(CSV_FILE_PATH)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kcv44zhjq6pZ"},"source":["グラフ描画に使う変数を設定します"]},{"cell_type":"code","metadata":{"id":"d-G3iKBGZSYF"},"source":["epochs = df[\"epoch\"].values\n","train_acc = df[\"accuracy\"].values\n","train_loss = df[\"loss\"].values\n","test_acc = df[\"val_accuracy\"].values\n","test_loss = df[\"val_loss\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HEA-bdqVlRG0"},"source":["###**損失関数の値**"]},{"cell_type":"code","metadata":{"id":"YNrSccLpZFwi"},"source":["plt.plot(epochs, train_loss, label=\"train data\")#　x座標データ　y座標データ　ラベル\n","plt.plot(epochs, test_loss, label=\"test data\")\n","plt.xlabel(\"epochs\")#　x軸ラベル\n","plt.ylabel(\"loss\\n(categorical crossentropy)\")#　y軸ラベル\n","plt.legend(loc=\"upper right\")#　右上に凡例\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSr7McQXlXAM"},"source":["###**画像分類の正答率**\n","\n","学習用データの曲線は、1.00にかなり近いところまでいってます。\n","検証用データ（今回はテストデータ）の曲線との差はグラフからはかなりあるように見えますが、0.02(2%)程度です。"]},{"cell_type":"code","metadata":{"id":"3o48HN2mZX8o"},"source":["plt.plot(epochs, train_acc, label=\"train data\")\n","plt.plot(epochs, test_acc, label=\"test data\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q28Cd8z0wtmm"},"source":["因みに学習用データを60000→600に減らすと、局所解に陥り検証データの曲線の精度が１０％以上落ちます。"]},{"cell_type":"markdown","metadata":{"id":"lsQ87co6lfLE"},"source":["##11. 学習済みモデルによる推論計算\n","学習済みモデルを用いて，testデータに対する推論計算を行い，分類結果を見てみます。"]},{"cell_type":"code","metadata":{"id":"O14yoyk3ZYEQ"},"source":[" for i in [0,1,2]:\n","    y_true = y_test[i]\n","    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n","    print(\"モデルによる予測\", \"(i=\"+str(i)+\"): \", y_pred)\n","    print(\"学習済みモデルに流す画像データのラベル\", \"(i=\"+str(i)+\"): \", y_true)\n","    print(\"学習済みモデルに流す画像データ\", \"(i=\"+str(i)+\"): \")\n","    plt.imshow(X_test[i], cmap='gray')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHahjMvAZcer"},"source":["fig = plt.figure(figsize=(12, 8))\n","\n","ROW = 4\n","COLUMN = 5\n","\n","for i in range(ROW * COLUMN):\n","    y_true = y_test[i]\n","    y_pred = model.predict_classes(X_test[i].reshape(1,28,28))[0]\n","    \n","    if y_true == y_pred:\n","        result = \"True\" # 正解\n","    else:\n","        result = \"False\" # ハズレ\n","    \n","    plt.subplot(ROW, COLUMN, i+1)\n","    plt.imshow(X_test[i], cmap='gray')\n","    plt.title(\"No.{} - {}\\ny_true:{}, y_pred:{}\".format(i, result, y_true, y_pred))\n","    plt.axis(\"off\")\n","\n","fig.tight_layout()\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jrAONdkIlzsz"},"source":["##12. 学習済みモデルの保存\n","Kerasでは，全てのニューラルネットワークモデルがkeras.models.Model()クラスのインスタンスとなっています．学習済みモデルmodelに対して， model.save()を実行することで「モデルの保存」が完了します．"]},{"cell_type":"code","metadata":{"id":"7gj8ZeZ2ZciV"},"source":["ins_path = 'trained_model_v0.h5'\n","model.save(ins_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lkkqR1Yk4A9"},"source":["##（発展）ディープラーニング  転移学習"]},{"cell_type":"markdown","metadata":{"id":"Th9oU1g8mG3j"},"source":["\n","\n","転移学習(Transfer Learning)はすでにある領域のデータで学習したモデルを活用しながら別の領域のデータを学習するもので、従来のディープラーニングをより生物の脳の学習機構に近づけた感じになっています。\n","\n","<img src = \"https://s3-ap-northeast-1.amazonaws.com/ledge-assets/media/wp-content/uploads/2020/05/08173933/fig1.png\" alt = \"filter\" height = \"250px\">\n","\n","出典：https://ledge.ai/transfer-learning/\n","\n","**実用例：Survival Prediction**\n","\n","参考：Transfer learning with convolutional neural networks for cancer survival prediction using gene-expression data（Guillermo López-García, José M. Jerez, Leonardo Franco, Francisco J. Veredas）\n","\n","https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230536\n","\n","肺癌を除く３１種類の異なる癌について、ゲノム配列と患者の生存率データを使って**予め学習した**CNNモデルを用意します。\n","肺癌のRNAシーケンスデータを使ってそのCNNモデルをファインチューニング（学習済みモデルの最終出力層を付け替え、入力層に近い部分と出力層のパラメータも変更する）します。\n","\n","\n","結果として、ゲノム配列を学習する際のCNNの弱点（隣接する塩基の関連性が見出しづらい等）を克服し、他の機械学習手法（MLNNsや他のML手法）よりも高パフォーマンスな予測ができたという報告がありました。"]},{"cell_type":"markdown","metadata":{"id":"Svsw91FKk6EN"},"source":["##（おまけ）ディープラーニング   深層強化学習"]},{"cell_type":"markdown","metadata":{"id":"qjFINpqjj_0G"},"source":["\n","\n","**特徴**\n","\n","1. 教師データが無くても学習できる\n","\n","1. 未知の環境に対しても学習できる\n","\n","\n","**例**\n","\n","  深層強化学習を使ったゲーム攻略\n","\n","https://qiita.com/yukiB/items/0a3faa759ca5561e12f8\n","\n","<img src = \"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F59864%2F6dcd9255-4f66-c606-23fd-d0002087ae80.gif?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&w=1400&fit=max&s=8e83c2114104c6626db0d67bfa2d12a0\" alt = \"filter\" height = \"250px\">\n","<img src = \"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F59864%2F78af77ed-882b-72c1-983b-1ba0036cb048.gif?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&w=1400&fit=max&s=b86f47064a104c8111f794aafe701a6d\" alt = \"filter\" height = \"250px\">"]}]}